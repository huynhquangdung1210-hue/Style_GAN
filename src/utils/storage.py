"""
Storage Client

Unified storage interface supporting MinIO, AWS S3, and local storage.
Provides a consistent API for storing and retrieving files across different backends.
"""

import asyncio
import aiofiles
import boto3
from botocore.exceptions import ClientError
from minio import Minio
from minio.error import S3Error
import structlog
from typing import Optional, Union, AsyncGenerator
import io
from pathlib import Path
from urllib.parse import urlparse
import os

from ..utils.config import get_settings

logger = structlog.get_logger()


class StorageError(Exception):
    """Custom exception for storage operations."""
    pass


class StorageClient:
    """
    Unified storage client supporting multiple backends.
    
    Backends:
    - MinIO: Self-hosted S3-compatible storage (default)
    - AWS S3: Amazon Web Services S3
    - Local: Local filesystem storage
    """
    
    def __init__(self):
        self.settings = get_settings().storage
        self._minio_client = None
        self._s3_client = None
        self._ensure_local_directory()
    
    def _ensure_local_directory(self):
        """Ensure local storage directory exists."""
        if self.settings.storage_type == "local":
            Path(self.settings.local_storage_path).mkdir(parents=True, exist_ok=True)
    
    @property
    def minio_client(self) -> Minio:
        """Get MinIO client with lazy initialization."""
        if self._minio_client is None:
            self._minio_client = Minio(
                endpoint=self.settings.minio_endpoint,
                access_key=self.settings.minio_access_key,
                secret_key=self.settings.minio_secret_key,
                secure=self.settings.minio_secure
            )
            # Ensure bucket exists
            try:
                if not self._minio_client.bucket_exists(self.settings.minio_bucket):
                    self._minio_client.make_bucket(self.settings.minio_bucket)
                    logger.info("Created MinIO bucket", bucket=self.settings.minio_bucket)
            except Exception as e:
                logger.warning("Failed to create MinIO bucket", error=str(e))
        
        return self._minio_client
    
    @property
    def s3_client(self):
        """Get S3 client with lazy initialization."""
        if self._s3_client is None:
            self._s3_client = boto3.client(
                's3',
                region_name=self.settings.aws_region,
                aws_access_key_id=self.settings.aws_access_key_id,
                aws_secret_access_key=self.settings.aws_secret_access_key,
                endpoint_url=self.settings.s3_endpoint_url
            )
        return self._s3_client
    
    async def upload_file(
        self,
        file_path: Union[str, Path],
        object_name: Optional[str] = None,
        content_type: Optional[str] = None
    ) -> str:\n        \"\"\"\n        Upload a file to the configured storage backend.\n        \n        Args:\n            file_path: Path to the file to upload\n            object_name: Object name in storage (defaults to filename)\n            content_type: MIME type of the file\n            \n        Returns:\n            URL or path to the uploaded file\n        \"\"\"\n        \n        file_path = Path(file_path)\n        if not file_path.exists():\n            raise StorageError(f\"File not found: {file_path}\")\n        \n        if object_name is None:\n            object_name = file_path.name\n        \n        logger.info(\n            \"Uploading file\",\n            backend=self.settings.storage_type,\n            file_path=str(file_path),\n            object_name=object_name\n        )\n        \n        try:\n            if self.settings.storage_type == \"minio\":\n                return await self._upload_to_minio(file_path, object_name, content_type)\n            elif self.settings.storage_type == \"s3\":\n                return await self._upload_to_s3(file_path, object_name, content_type)\n            elif self.settings.storage_type == \"local\":\n                return await self._upload_to_local(file_path, object_name)\n            else:\n                raise StorageError(f\"Unsupported storage type: {self.settings.storage_type}\")\n                \n        except Exception as e:\n            logger.error(\"File upload failed\", error=str(e))\n            raise StorageError(f\"Upload failed: {str(e)}\")\n    \n    async def upload_bytes(\n        self,\n        data: bytes,\n        object_name: str,\n        content_type: Optional[str] = None\n    ) -> str:\n        \"\"\"\n        Upload bytes data to the configured storage backend.\n        \n        Args:\n            data: Bytes data to upload\n            object_name: Object name in storage\n            content_type: MIME type of the data\n            \n        Returns:\n            URL or path to the uploaded data\n        \"\"\"\n        \n        logger.info(\n            \"Uploading bytes\",\n            backend=self.settings.storage_type,\n            object_name=object_name,\n            size=len(data)\n        )\n        \n        try:\n            if self.settings.storage_type == \"minio\":\n                return await self._upload_bytes_to_minio(data, object_name, content_type)\n            elif self.settings.storage_type == \"s3\":\n                return await self._upload_bytes_to_s3(data, object_name, content_type)\n            elif self.settings.storage_type == \"local\":\n                return await self._upload_bytes_to_local(data, object_name)\n            else:\n                raise StorageError(f\"Unsupported storage type: {self.settings.storage_type}\")\n                \n        except Exception as e:\n            logger.error(\"Bytes upload failed\", error=str(e))\n            raise StorageError(f\"Upload failed: {str(e)}\")\n    \n    async def download_file(self, object_name: str, local_path: Optional[Union[str, Path]] = None) -> Union[str, bytes]:\n        \"\"\"\n        Download a file from the configured storage backend.\n        \n        Args:\n            object_name: Object name in storage\n            local_path: Local path to save file (if None, returns bytes)\n            \n        Returns:\n            Local file path or bytes data\n        \"\"\"\n        \n        logger.info(\n            \"Downloading file\",\n            backend=self.settings.storage_type,\n            object_name=object_name\n        )\n        \n        try:\n            if self.settings.storage_type == \"minio\":\n                return await self._download_from_minio(object_name, local_path)\n            elif self.settings.storage_type == \"s3\":\n                return await self._download_from_s3(object_name, local_path)\n            elif self.settings.storage_type == \"local\":\n                return await self._download_from_local(object_name, local_path)\n            else:\n                raise StorageError(f\"Unsupported storage type: {self.settings.storage_type}\")\n                \n        except Exception as e:\n            logger.error(\"File download failed\", error=str(e))\n            raise StorageError(f\"Download failed: {str(e)}\")\n    \n    async def delete_file(self, object_name: str) -> bool:\n        \"\"\"\n        Delete a file from the configured storage backend.\n        \n        Args:\n            object_name: Object name in storage\n            \n        Returns:\n            True if deleted successfully\n        \"\"\"\n        \n        logger.info(\n            \"Deleting file\",\n            backend=self.settings.storage_type,\n            object_name=object_name\n        )\n        \n        try:\n            if self.settings.storage_type == \"minio\":\n                return await self._delete_from_minio(object_name)\n            elif self.settings.storage_type == \"s3\":\n                return await self._delete_from_s3(object_name)\n            elif self.settings.storage_type == \"local\":\n                return await self._delete_from_local(object_name)\n            else:\n                raise StorageError(f\"Unsupported storage type: {self.settings.storage_type}\")\n                \n        except Exception as e:\n            logger.error(\"File deletion failed\", error=str(e))\n            return False\n    \n    def get_file_url(self, object_name: str) -> str:\n        \"\"\"\n        Get public URL for a file.\n        \n        Args:\n            object_name: Object name in storage\n            \n        Returns:\n            Public URL or local path\n        \"\"\"\n        \n        if self.settings.storage_type == \"minio\":\n            protocol = \"https\" if self.settings.minio_secure else \"http\"\n            return f\"{protocol}://{self.settings.minio_endpoint}/{self.settings.minio_bucket}/{object_name}\"\n        elif self.settings.storage_type == \"s3\":\n            if self.settings.s3_endpoint_url:\n                return f\"{self.settings.s3_endpoint_url}/{self.settings.s3_bucket}/{object_name}\"\n            else:\n                return f\"https://s3.{self.settings.aws_region}.amazonaws.com/{self.settings.s3_bucket}/{object_name}\"\n        elif self.settings.storage_type == \"local\":\n            return str(Path(self.settings.local_storage_path) / object_name)\n        else:\n            raise StorageError(f\"Unsupported storage type: {self.settings.storage_type}\")\n    \n    # MinIO implementation\n    async def _upload_to_minio(self, file_path: Path, object_name: str, content_type: Optional[str]) -> str:\n        \"\"\"Upload file to MinIO.\"\"\"\n        loop = asyncio.get_event_loop()\n        \n        def _upload():\n            self.minio_client.fput_object(\n                bucket_name=self.settings.minio_bucket,\n                object_name=object_name,\n                file_path=str(file_path),\n                content_type=content_type\n            )\n        \n        await loop.run_in_executor(None, _upload)\n        return self.get_file_url(object_name)\n    \n    async def _upload_bytes_to_minio(self, data: bytes, object_name: str, content_type: Optional[str]) -> str:\n        \"\"\"Upload bytes to MinIO.\"\"\"\n        loop = asyncio.get_event_loop()\n        \n        def _upload():\n            self.minio_client.put_object(\n                bucket_name=self.settings.minio_bucket,\n                object_name=object_name,\n                data=io.BytesIO(data),\n                length=len(data),\n                content_type=content_type\n            )\n        \n        await loop.run_in_executor(None, _upload)\n        return self.get_file_url(object_name)\n    \n    async def _download_from_minio(self, object_name: str, local_path: Optional[Path]) -> Union[str, bytes]:\n        \"\"\"Download file from MinIO.\"\"\"\n        loop = asyncio.get_event_loop()\n        \n        if local_path:\n            def _download():\n                self.minio_client.fget_object(\n                    bucket_name=self.settings.minio_bucket,\n                    object_name=object_name,\n                    file_path=str(local_path)\n                )\n            \n            await loop.run_in_executor(None, _download)\n            return str(local_path)\n        else:\n            def _download_data():\n                response = self.minio_client.get_object(\n                    bucket_name=self.settings.minio_bucket,\n                    object_name=object_name\n                )\n                data = response.read()\n                response.close()\n                response.release_conn()\n                return data\n            \n            return await loop.run_in_executor(None, _download_data)\n    \n    async def _delete_from_minio(self, object_name: str) -> bool:\n        \"\"\"Delete file from MinIO.\"\"\"\n        loop = asyncio.get_event_loop()\n        \n        def _delete():\n            self.minio_client.remove_object(\n                bucket_name=self.settings.minio_bucket,\n                object_name=object_name\n            )\n        \n        try:\n            await loop.run_in_executor(None, _delete)\n            return True\n        except S3Error:\n            return False\n    \n    # S3 implementation\n    async def _upload_to_s3(self, file_path: Path, object_name: str, content_type: Optional[str]) -> str:\n        \"\"\"Upload file to S3.\"\"\"\n        loop = asyncio.get_event_loop()\n        \n        def _upload():\n            extra_args = {}\n            if content_type:\n                extra_args['ContentType'] = content_type\n            \n            self.s3_client.upload_file(\n                str(file_path),\n                self.settings.s3_bucket,\n                object_name,\n                ExtraArgs=extra_args\n            )\n        \n        await loop.run_in_executor(None, _upload)\n        return self.get_file_url(object_name)\n    \n    async def _upload_bytes_to_s3(self, data: bytes, object_name: str, content_type: Optional[str]) -> str:\n        \"\"\"Upload bytes to S3.\"\"\"\n        loop = asyncio.get_event_loop()\n        \n        def _upload():\n            extra_args = {}\n            if content_type:\n                extra_args['ContentType'] = content_type\n            \n            self.s3_client.upload_fileobj(\n                io.BytesIO(data),\n                self.settings.s3_bucket,\n                object_name,\n                ExtraArgs=extra_args\n            )\n        \n        await loop.run_in_executor(None, _upload)\n        return self.get_file_url(object_name)\n    \n    async def _download_from_s3(self, object_name: str, local_path: Optional[Path]) -> Union[str, bytes]:\n        \"\"\"Download file from S3.\"\"\"\n        loop = asyncio.get_event_loop()\n        \n        if local_path:\n            def _download():\n                self.s3_client.download_file(\n                    self.settings.s3_bucket,\n                    object_name,\n                    str(local_path)\n                )\n            \n            await loop.run_in_executor(None, _download)\n            return str(local_path)\n        else:\n            def _download_data():\n                response = self.s3_client.get_object(\n                    Bucket=self.settings.s3_bucket,\n                    Key=object_name\n                )\n                return response['Body'].read()\n            \n            return await loop.run_in_executor(None, _download_data)\n    \n    async def _delete_from_s3(self, object_name: str) -> bool:\n        \"\"\"Delete file from S3.\"\"\"\n        loop = asyncio.get_event_loop()\n        \n        def _delete():\n            self.s3_client.delete_object(\n                Bucket=self.settings.s3_bucket,\n                Key=object_name\n            )\n        \n        try:\n            await loop.run_in_executor(None, _delete)\n            return True\n        except ClientError:\n            return False\n    \n    # Local storage implementation\n    async def _upload_to_local(self, file_path: Path, object_name: str) -> str:\n        \"\"\"Upload file to local storage.\"\"\"\n        target_path = Path(self.settings.local_storage_path) / object_name\n        target_path.parent.mkdir(parents=True, exist_ok=True)\n        \n        async with aiofiles.open(file_path, 'rb') as src:\n            async with aiofiles.open(target_path, 'wb') as dst:\n                async for chunk in src:\n                    await dst.write(chunk)\n        \n        return str(target_path)\n    \n    async def _upload_bytes_to_local(self, data: bytes, object_name: str) -> str:\n        \"\"\"Upload bytes to local storage.\"\"\"\n        target_path = Path(self.settings.local_storage_path) / object_name\n        target_path.parent.mkdir(parents=True, exist_ok=True)\n        \n        async with aiofiles.open(target_path, 'wb') as f:\n            await f.write(data)\n        \n        return str(target_path)\n    \n    async def _download_from_local(self, object_name: str, local_path: Optional[Path]) -> Union[str, bytes]:\n        \"\"\"Download file from local storage.\"\"\"\n        source_path = Path(self.settings.local_storage_path) / object_name\n        \n        if not source_path.exists():\n            raise StorageError(f\"File not found: {object_name}\")\n        \n        if local_path:\n            local_path = Path(local_path)\n            local_path.parent.mkdir(parents=True, exist_ok=True)\n            \n            async with aiofiles.open(source_path, 'rb') as src:\n                async with aiofiles.open(local_path, 'wb') as dst:\n                    async for chunk in src:\n                        await dst.write(chunk)\n            \n            return str(local_path)\n        else:\n            async with aiofiles.open(source_path, 'rb') as f:\n                return await f.read()\n    \n    async def _delete_from_local(self, object_name: str) -> bool:\n        \"\"\"Delete file from local storage.\"\"\"\n        file_path = Path(self.settings.local_storage_path) / object_name\n        \n        try:\n            if file_path.exists():\n                file_path.unlink()\n            return True\n        except Exception:\n            return False\n\n\n# Global storage client instance\n_storage_client: Optional[StorageClient] = None\n\n\ndef get_storage_client() -> StorageClient:\n    \"\"\"Get storage client (singleton pattern).\"\"\"\n    global _storage_client\n    \n    if _storage_client is None:\n        _storage_client = StorageClient()\n    \n    return _storage_client\n\n\n# Convenience functions\nasync def upload_file(file_path: Union[str, Path], object_name: Optional[str] = None) -> str:\n    \"\"\"Upload a file using the default storage client.\"\"\"\n    client = get_storage_client()\n    return await client.upload_file(file_path, object_name)\n\n\nasync def upload_bytes(data: bytes, object_name: str, content_type: Optional[str] = None) -> str:\n    \"\"\"Upload bytes using the default storage client.\"\"\"\n    client = get_storage_client()\n    return await client.upload_bytes(data, object_name, content_type)\n\n\nasync def download_file(object_name: str, local_path: Optional[Union[str, Path]] = None) -> Union[str, bytes]:\n    \"\"\"Download a file using the default storage client.\"\"\"\n    client = get_storage_client()\n    return await client.download_file(object_name, local_path)\n\n\nasync def delete_file(object_name: str) -> bool:\n    \"\"\"Delete a file using the default storage client.\"\"\"\n    client = get_storage_client()\n    return await client.delete_file(object_name)\n\n\ndef get_file_url(object_name: str) -> str:\n    \"\"\"Get file URL using the default storage client.\"\"\"\n    client = get_storage_client()\n    return client.get_file_url(object_name)\n